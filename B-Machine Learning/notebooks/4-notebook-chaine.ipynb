{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaine de traitements\n",
    "\n",
    "Une chaine de traitements est composée de différents maillons\n",
    "\n",
    "<img src=\"fig/chaine2.png\">\n",
    "\n",
    "> L'impact des pré-traitements sur la performance finale est souvent très important\n",
    "\n",
    "Nous allons donc étudier les pré-traitement les plus classiques et la manière de les implémenter proprement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from outils.frontiere import *\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Transformation des variables de description\n",
    "\n",
    "Les données brutes sont souvent incomplètes et bruitées, parfois trop spécifiques etc...\n",
    "L'exploitation de ces informations requière leur transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## A.1. Enrichissement et transformation des données\n",
    "\n",
    "### A.1.1. Encodage des variables discrètes\n",
    "\n",
    "Les variables descriptives sont souvent discrètes... Or les approches de machine learning ne savent pas gérer ces informations là (sauf certains arbres).\n",
    "\n",
    "1. Charger des données discrètes   \n",
    "    * prédiction de récidive de cancer\n",
    "2. Afficher les 3 premières lignes (et bien comprendre qu'on a un problème par rapport aux données manipulées jusqu'ici)\n",
    "3. Transformer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"'40-49'\" \"'premeno'\" \"'15-19'\" \"'0-2'\" \"'yes'\" \"'3'\" \"'right'\"\n",
      "  \"'left_up'\" \"'no'\"]\n",
      " [\"'50-59'\" \"'ge40'\" \"'15-19'\" \"'0-2'\" \"'no'\" \"'1'\" \"'right'\" \"'central'\"\n",
      "  \"'no'\"]\n",
      " [\"'50-59'\" \"'ge40'\" \"'35-39'\" \"'0-2'\" \"'no'\" \"'2'\" \"'left'\" \"'left_low'\"\n",
      "  \"'no'\"]] [[\"'recurrence-events'\"]\n",
      " [\"'no-recurrence-events'\"]\n",
      " [\"'recurrence-events'\"]]\n"
     ]
    }
   ],
   "source": [
    "# récupération de données discrètes\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"data/breast-cancer.csv\"\n",
    "data = pd.read_csv(filename, header=None).values\n",
    "\n",
    "Xbrut = data[:,:-1]\n",
    "Ybrut = data[:,-1:]\n",
    "\n",
    "print(Xbrut[:3,:], Ybrut[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catégories: \n",
      " [array([\"'20-29'\", \"'30-39'\", \"'40-49'\", \"'50-59'\", \"'60-69'\", \"'70-79'\"],\n",
      "      dtype=object), array([\"'ge40'\", \"'lt40'\", \"'premeno'\"], dtype=object), array([\"'0-4'\", \"'10-14'\", \"'15-19'\", \"'20-24'\", \"'25-29'\", \"'30-34'\",\n",
      "       \"'35-39'\", \"'40-44'\", \"'45-49'\", \"'5-9'\", \"'50-54'\"], dtype=object), array([\"'0-2'\", \"'12-14'\", \"'15-17'\", \"'24-26'\", \"'3-5'\", \"'6-8'\",\n",
      "       \"'9-11'\"], dtype=object), array([\"'no'\", \"'yes'\", nan], dtype=object), array([\"'1'\", \"'2'\", \"'3'\"], dtype=object), array([\"'left'\", \"'right'\"], dtype=object), array([\"'central'\", \"'left_low'\", \"'left_up'\", \"'right_low'\",\n",
      "       \"'right_up'\", nan], dtype=object), array([\"'no'\", \"'yes'\"], dtype=object)]\n",
      "Echantillon: \n",
      " [[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]] [0. 1. 0.]\n",
      "Comparaison des dimensions: \n",
      " (286, 9) (286, 43)\n"
     ]
    }
   ],
   "source": [
    "# transformation des données\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "enc.fit(Xbrut)\n",
    "\n",
    "print(\"Catégories: \\n\",enc.categories_)\n",
    "X = enc.transform(Xbrut) # transformation des X\n",
    "\n",
    "enc2 = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "Y = enc2.fit_transform(Ybrut)[:,0] # même opération (tout en une ligne) pour les Y\n",
    "\n",
    "print(\"Echantillon: \\n\",X[:3,:], Y[:3])\n",
    "\n",
    "print(\"Comparaison des dimensions: \\n\",Xbrut.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse et performances\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# définition du modèle\n",
    "mod = SVC(kernel=\"linear\")\n",
    "n_fold = 5\n",
    "scores = cross_val_score(mod, X, Y, cv=n_fold, scoring='accuracy') # tout est caché dedans :)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sait maintenant qu'il faut se méfier de l'accuracy dans les cas déséquilibré...\n",
    "# vérification sur la balance des étiquettes \n",
    "print(np.histogram(Y,2))\n",
    "\n",
    "# calcul du score f1\n",
    "scores = cross_val_score(mod, X, Y, cv=n_fold, scoring='f1') # tout est caché dedans :)\n",
    "print(scores) # ça va"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1.2 Création de nouvelles variables\n",
    "\n",
    "Sur l'exemples de l'échiquier, si on ajoute un descripteur qui change de valeur sur le modulo 2 de la coordonnées des points... Le problème devient séparable linéairement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des données\n",
    "centers = [[float(i),float(j)] for i in range(5) for j in range(5)]\n",
    "print(centers)\n",
    "clusters_std = 0.2\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0)\n",
    "y = (y % 2)*2 - 1 # chaque centre = 1 classe => Echiquier binaire\n",
    "\n",
    "print(X.shape)\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction d'un classifieur linéaire\n",
    "\n",
    "mod = svm.SVC(kernel=\"linear\")\n",
    "mod.fit(X,y)\n",
    "\n",
    "plt.figure()\n",
    "plot_frontiere(X,y,mod)\n",
    "plt.scatter(X[:,0],X[:,1],c=y)\n",
    "\n",
    "# plt.savefig(\"fig/checkers.pdf\")\n",
    "\n",
    "sc = cross_val_score(mod,X,y)\n",
    "print(\"Scores : \", sc)\n",
    "\n",
    "# => Les données ne sont pas séparable linéairemnet !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajout de variables (très utiles)\n",
    "\n",
    "Xi = np.reshape([(np.floor(i)%2)*2-1 for i in X[:,0]+0.5], (-1,1))\n",
    "Xj = np.reshape([(np.floor(i)%2)*2-1 for i in X[:,1]+0.5], (-1,1))\n",
    "\n",
    "Xe = np.concatenate((X,Xi,Xj), axis = 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(Xe[:12,:])\n",
    "# plt.savefig(\"fig/checkers_Xe.pdf\")\n",
    "\n",
    "sc = cross_val_score(mod,Xe,y)\n",
    "print(\"Scores : \", sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1.3 Discrétisation de variables continues\n",
    "\n",
    "Il est parfois difficile de tirer parti des informations continues et plus simple de créer des variables encodant directement l'appartenance à un segment.\n",
    "\n",
    "e.g. : données étalées entre 1 et 10, avec:\n",
    "* un peu de points uniformément répartis entre 1 et 5\n",
    "* beaucoup de points centrés en 7.5 avec une faible dispersion\n",
    "* beaucoup de points centrés en 9 avec une faible dispersion\n",
    "\n",
    "$\\Rightarrow$ ce type de distribution destabilise les approches de ML\n",
    "\n",
    "1. La fonction qui permet de faire ça est: `KBinsDiscretizer`\n",
    "2. Génerer des données et tester cette fonction\n",
    "3. [OPT] Réfléchir au pont entre modèle linéaire et arbres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# générer des données 1D \n",
    "\n",
    "# tester la fonction et afficher la matrice créée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2. Normalisation des données (par colonne)\n",
    "\n",
    "Soit des données tabulaires classiques:\n",
    "$$X = \\begin{pmatrix}  x_{11}& x_{12} &  \\ldots & x_{1d}  \\\\\n",
    "x_{21}& x_{22} & \\ldots & x_{2d} \\\\\n",
    "\\vdots& \\vdots & \\ddots &\\vdots \\\\\n",
    "x_{n1}& x_{n2} & \\ldots & x_{nd}  \\\\\n",
    "\\end{pmatrix} ,\\qquad\n",
    "Y = \\begin{pmatrix}  y_{1} \\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{n} \\\\\n",
    "\\end{pmatrix} ,\\qquad y_i\\in \\mathcal Y\n",
    "$$\n",
    "\n",
    "Dans la plupart des cas, le problème vient des $X_j$ :\n",
    "\n",
    "* qui ne sont pas codés dans les mêmes échelles. e.g. colonne $i$ en $10^{-5}$, colonne $j$ en $10^{-9}$ \n",
    "* qui ont simplement un biais trop important, e.g. valeur entre $1050$ et $1070$\n",
    "\n",
    "Les algorithmes de ML sont souvent destabilités par ces écarts de valeur. Il faut normaliser pour obtenir de bonnes performances\n",
    "\n",
    "On utilise presque tout le temps une normlisation standard gaussienne consistant à centrer réduire les $X_j \\Rightarrow \\tilde{X}_j \\sim \\mathcal N(0,1)$.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"data/winequality-red.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des performances avec et sans normalisation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.values[:,:-1]\n",
    "Y = data.values[:,-1]\n",
    "# remise en forme des Y entre 0 et nClasses\n",
    "val = np.unique(Y)\n",
    "transf = dict(zip(val,np.arange(len(val)))) # mapping [x,y,z] => [0,1,2]\n",
    "Y = np.vectorize(transf.get)(Y)             # application de la transformation\n",
    "\n",
    "mod = SVC()\n",
    "sc = cross_val_score( mod, X, Y, scoring='accuracy')\n",
    "\n",
    "print(\"Scores \",sc,sc.mean())\n",
    "\n",
    "# normalisation des données\n",
    "scal = StandardScaler()\n",
    "\n",
    "# 1. Appliquer la transformation (cf doc)\n",
    "\n",
    "# 2. Calculer la performance\n",
    "\n",
    "###  TODO  ###\n",
    "\n",
    "print(\"Scores sur données normalisées \",sc,sc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question d'ouverture**\n",
    "\n",
    "L'impact de la normalisation est-il le même sur tous les classifieurs?\n",
    "\n",
    "Non, évidemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb # !pip install xgboost # en cas de besoin\n",
    "\n",
    "bst = xgb.XGBClassifier()\n",
    "sc = cross_val_score( bst, X, Y, scoring='accuracy')\n",
    "print(\"xgboost : \",sc, sc.mean())\n",
    "\n",
    "sc = cross_val_score( bst, Xn, Y, scoring='accuracy')\n",
    "print(\"xgboost (normalisé): \",sc, sc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3. Normalisation par individu\n",
    "\n",
    "Sur certaines applications spécifiques comme la classification de signaux ou les données textuelles, on normalise les individus afin de les rendre comparables\n",
    "\n",
    "* par défaut, un texte de 100 mots n'est pas comparable avec un texte de 1000 mots\n",
    "* les log à la station chatelet dans une journée de semaine ne sont pas comparables avec un week-end\n",
    "\n",
    "Les deux normalisations les plus connues (et utilisées) sont:\n",
    "\n",
    "1. La normalisation probabiliste (les variables de l'individu somme à 1), on fait une hypothèse multinomiale sur les variables\n",
    "    * pour le texte notamment\n",
    "1. La normalisation min-max => 0-1\n",
    "    * souvent pour les signaux\n",
    "    * Evidemment, en fonction de l'application visée, ça peut être utile ou au contraire néfaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"data/Beef_TRAIN.tsv\"\n",
    "data = pd.read_csv(filename, header=None, sep='\\t')\n",
    "\n",
    "print(np.unique(data.values[:,0], return_counts=True))\n",
    "\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = data.values[:,1:]\n",
    "Y = data.values[:,0]\n",
    "# remise en forme des Y entre 0 et nClasses\n",
    "val = np.unique(Y)\n",
    "transf = dict(zip(val,np.arange(len(val)))) # mapping [x,y,z] => [0,1,2]\n",
    "Y = np.vectorize(transf.get)(Y)             # application de la transformation\n",
    "\n",
    "mod = SVC()\n",
    "sc = cross_val_score( mod, X, Y, scoring='accuracy')\n",
    "\n",
    "print(\"Scores \",sc,sc.mean())\n",
    "\n",
    "# normalisation des données\n",
    "scal = MinMaxScaler()\n",
    "#scal = StandardScaler() # vous pouvez switcher pour voir...\n",
    "Xn = scal.fit_transform(X)\n",
    "sc = cross_val_score( mod, Xn, Y, scoring='accuracy')\n",
    "\n",
    "print(\"Scores sur données normalisées \",sc,sc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Etude approfondie du cas Auto-mpg\n",
    "\n",
    "Effectuer le même genre d'opération sur le jeu de données UCI Auto MPG, consistant à prédire la consommation (MPG) d'un ensemble de voitures.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/auto+mpg\n",
    "\n",
    "1. Tester un régresseur de base sur le sous-ensemble de colonnes correspondant à des données numériques \n",
    "2. Encoder les colonnes catégorielles et comparer la performance\n",
    "3. Que penser des colonnes de date et de cylindrée?\n",
    "    * Tester leur prise en compte numérique *vs* leur prise en compte catégorielle\n",
    "4. La dernière colonne est séparable en plusieurs (marque, modèle)\n",
    "    * Quel impact sur les performances\n",
    "5. Imaginer d'autres manières de prendre en compte les valeurs manquantes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>90</td>\n",
       "      <td>2264</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet vega 2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95</td>\n",
       "      <td>2228</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>toyota corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2046</td>\n",
       "      <td>19.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ford pinto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2634</td>\n",
       "      <td>13.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>amc gremlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105</td>\n",
       "      <td>3439</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3329</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>19.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3302</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino 500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100</td>\n",
       "      <td>3288</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>amc matador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>4209</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet impala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>175</td>\n",
       "      <td>4464</td>\n",
       "      <td>11.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>pontiac catalina brougham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>153</td>\n",
       "      <td>4154</td>\n",
       "      <td>13.5</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>ford galaxie 500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mpg  cylinders  displacement horsepower  weight  acceleration  \\\n",
       "30  28.0          4         140.0         90    2264          15.5   \n",
       "31  25.0          4         113.0         95    2228          14.0   \n",
       "32  25.0          4          98.0          ?    2046          19.0   \n",
       "33  19.0          6         232.0        100    2634          13.0   \n",
       "34  16.0          6         225.0        105    3439          15.5   \n",
       "35  17.0          6         250.0        100    3329          15.5   \n",
       "36  19.0          6         250.0         88    3302          15.5   \n",
       "37  18.0          6         232.0        100    3288          15.5   \n",
       "38  14.0          8         350.0        165    4209          12.0   \n",
       "39  14.0          8         400.0        175    4464          11.5   \n",
       "40  14.0          8         351.0        153    4154          13.5   \n",
       "\n",
       "    model year  origin                   car name  \n",
       "30          71       1        chevrolet vega 2300  \n",
       "31          71       3              toyota corona  \n",
       "32          71       1                 ford pinto  \n",
       "33          71       1                amc gremlin  \n",
       "34          71       1  plymouth satellite custom  \n",
       "35          71       1  chevrolet chevelle malibu  \n",
       "36          71       1            ford torino 500  \n",
       "37          71       1                amc matador  \n",
       "38          71       1           chevrolet impala  \n",
       "39          71       1  pontiac catalina brougham  \n",
       "40          71       1           ford galaxie 500  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des données (1/2)\n",
    "\n",
    "filename = \"data/auto-mpg.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "X = data.values[:,1:]\n",
    "Y = data.values[:,0]\n",
    "\n",
    "# la colonne 2 contient des données manquantes (?)... Et elle est encodée en chaine de caractères...\n",
    "data.loc[30:40, :] # equiv. dans pandas de: print(X[30:40])\n",
    "\n",
    "# alternative : data.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1. La gestion des données manquantes\n",
    "\n",
    "De nombreux jeux de données présentent des données manquantes, souvent dans une ou deux colonnes et sur quelques lignes. La question de savoir comment traiter ce cas de figure occupe beaucoup la communauté.\n",
    "\n",
    "1. Du point de vue théorique, ça relève de l'algorithme EM pour l'estimation de valeur manquante\n",
    "2. Du point de vue très opérationnel, on peut:\n",
    "    * supprimer les lignes affectées\n",
    "    * affecter la valeur moyenne de la colonne aux cases manquantes (cf case ci-dessous)\n",
    "3. D'autres stratégies assez simples sont disponibles dans sk-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 140.0 90 2264 15.5 71 1 'chevrolet vega 2300']\n",
      " [4 113.0 95 2228 14.0 71 3 'toyota corona']\n",
      " [4 98.0 104.0 2046 19.0 71 1 'ford pinto']\n",
      " [6 232.0 100 2634 13.0 71 1 'amc gremlin']\n",
      " [6 225.0 105 3439 15.5 71 1 'plymouth satellite custom']\n",
      " [6 250.0 100 3329 15.5 71 1 'chevrolet chevelle malibu']\n",
      " [6 250.0 88 3302 15.5 71 1 'ford torino 500']\n",
      " [6 232.0 100 3288 15.5 71 1 'amc matador']\n",
      " [8 350.0 165 4209 12.0 71 1 'chevrolet impala']\n",
      " [8 400.0 175 4464 11.5 71 1 'pontiac catalina brougham']]\n"
     ]
    }
   ],
   "source": [
    "# Chargement des données (2/2)\n",
    "\n",
    "# On propose de les remplacer par la valeur moyenne de la colonne [A LA MAIN]\n",
    "# 1. On remplace par des 0\n",
    "X[:,2] = [0 if X[i,2] == '?' else int(X[i,2]) for i in range (len(X))]\n",
    "# 2. On remplace par la moyenne\n",
    "m = np.round(X[:,2].sum()/np.where(X[:,2]>0, 1, 0).sum()) # 104\n",
    "X[:,2] = np.where(X[:,2]==0, m, X[:,2])\n",
    "\n",
    "print(X[30:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégies alternatives **à maitriser** :\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '?'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_h/xz4nr0h53dj3x3tygxjnzl540000gn/T/ipykernel_7884/245480338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimp_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# attention, fonction par robuste aux str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mXnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# que se passe-t-il?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    362\u001b[0m             )\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    315\u001b[0m                     )\n\u001b[1;32m    316\u001b[0m                 )\n\u001b[0;32m--> 317\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: '?'"
     ]
    }
   ],
   "source": [
    "# application directe de la fonction:\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = data.values[:,1:]\n",
    "Y = data.values[:,0]\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values='?', strategy='mean') # attention, fonction par robuste aux str\n",
    "Xnum = imp_mean.fit_transform(X)\n",
    "\n",
    "# que se passe-t-il?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.00000000e+00 1.40000000e+02 9.00000000e+01 2.26400000e+03\n",
      "  1.55000000e+01 7.10000000e+01]\n",
      " [4.00000000e+00 1.13000000e+02 9.50000000e+01 2.22800000e+03\n",
      "  1.40000000e+01 7.10000000e+01]\n",
      " [4.00000000e+00 9.80000000e+01 1.04469388e+02 2.04600000e+03\n",
      "  1.90000000e+01 7.10000000e+01]\n",
      " [6.00000000e+00 2.32000000e+02 1.00000000e+02 2.63400000e+03\n",
      "  1.30000000e+01 7.10000000e+01]\n",
      " [6.00000000e+00 2.25000000e+02 1.05000000e+02 3.43900000e+03\n",
      "  1.55000000e+01 7.10000000e+01]\n",
      " [6.00000000e+00 2.50000000e+02 1.00000000e+02 3.32900000e+03\n",
      "  1.55000000e+01 7.10000000e+01]\n",
      " [6.00000000e+00 2.50000000e+02 8.80000000e+01 3.30200000e+03\n",
      "  1.55000000e+01 7.10000000e+01]\n",
      " [6.00000000e+00 2.32000000e+02 1.00000000e+02 3.28800000e+03\n",
      "  1.55000000e+01 7.10000000e+01]\n",
      " [8.00000000e+00 3.50000000e+02 1.65000000e+02 4.20900000e+03\n",
      "  1.20000000e+01 7.10000000e+01]\n",
      " [8.00000000e+00 4.00000000e+02 1.75000000e+02 4.46400000e+03\n",
      "  1.15000000e+01 7.10000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Version corrigée: il faut passer les données en numérique\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "Xnum = data.values[:,1:7] # récupération des données avec cases manquantes\n",
    "# 1. On remplace les ? par des np.nan + transformation numérique\n",
    "Xnum[:,2] = [np.nan if Xnum[i,2] == '?' else int(X[i,2]) for i in range (len(Xnum))]\n",
    "# 2. On utilise un outil sklearn\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean') # attention, fonction par robuste aux str\n",
    "Xnum = imp_mean.fit_transform(Xnum)\n",
    "\n",
    "print(Xnum[30:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2. Analyse du contenu \n",
    "\n",
    "Nous nous intéressons d'abord à la dernière colonne qui est problématique (car non numérique)... Puis à toutes les autres colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combien de valeurs uniques: 305 (nb val= 398 )\n"
     ]
    }
   ],
   "source": [
    "# analyse de la dernière colonne:\n",
    "print(\"Combien de valeurs uniques:\", len(np.unique(X[:,-1])), \"(nb val=\",len(X),\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chevrolet' 'buick' 'plymouth' 'amc' 'ford' 'ford']\n"
     ]
    }
   ],
   "source": [
    "#Il faut sans doute se limiter à la marque:\n",
    "# remplacer le nom complet du modèle par la marque seule (cette information peut avoir de la valeur pour estimer la consommation)\n",
    "\n",
    "###  TODO  ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_h/xz4nr0h53dj3x3tygxjnzl540000gn/T/ipykernel_7884/1461341404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# colonne numériques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# extraction des colonnes à valeurs discrètes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mconso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ravel_and_check_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0mbin_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniform_bins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_bin_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;31m# Histogram is an integer or a float array depending on the weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_bin_edges\u001b[0;34m(a, bins, range, weights)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`bins` must be positive, when an integer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_outer_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36m_get_outer_edges\u001b[0;34m(a, range)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mfirst_edge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_edge\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             raise ValueError(\n\u001b[1;32m    324\u001b[0m                 \"autodetected range of [{}, {}] is not finite\".format(first_edge, last_edge))\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2880x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Analyse des colonnes (histogramme)\n",
    "plt.figure(figsize=[5*X.shape[1],5])\n",
    "for i in range(X.shape[1]):\n",
    "    plt.subplot(1,X.shape[1],i+1)\n",
    "    # plt.figure()\n",
    "    if i<X.shape[1]-1: # colonne numériques\n",
    "        nbins = np.minimum(len(np.unique(X[:,i])), 12) # extraction des colonnes à valeurs discrètes\n",
    "        [e,x] = np.histogram(X[:,i], nbins)\n",
    "        x[-1] += 0.001\n",
    "        conso = [Y[np.logical_and(X[:,i]>=x[j], X[:,i]<x[j+1])].mean() for j in range(len(e))]\n",
    "        # print(e,x)\n",
    "        plt.bar(np.arange(len(e)),e)\n",
    "        plt.bar(np.arange(len(e)),conso, alpha=0.5)\n",
    "        plt.title('Colonne '+str(i))\n",
    "    else: # colonnes textuelles\n",
    "        val,e = np.unique(X[:,-1], return_counts=True)\n",
    "        plt.bar(np.arange(len(e)),e)\n",
    "        conso = [Y[X[:,-1] == v].mean() for v in val]\n",
    "        plt.bar(np.arange(len(e)),conso, alpha=0.5)\n",
    "        plt.title('Colonne '+str(i))\n",
    "\n",
    "#plt.savefig('fig/auto-mpg-all.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3. Performances de base puis enrichissement des données\n",
    "\n",
    "On calcule d'abord une performance sur les données numériques faciles à exploiter... Puis on va enrichir la représentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modèle de référence :  [-0.20275314 -0.16638221 -0.09926274 -0.13836117 -0.12857235] -0.14706632190591318\n",
      "(398, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# Construction d'un modèle de référence sur les colonnes numériques\n",
    "Xr = Xnum[:,1:6]\n",
    "mod = Ridge()\n",
    "\n",
    "sc = cross_val_score( mod, Xr, Y, scoring='neg_mean_absolute_percentage_error')\n",
    "\n",
    "print(\"modèle de référence : \",sc, sc.mean())\n",
    "\n",
    "print(Xr.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 5)\n",
      "Ajout colonne =  0\n",
      "modèle de référence :  [-0.18306665 -0.1337533  -0.10948645 -0.12233257 -0.11801171] -0.13333013718506842\n",
      "(398, 13)\n",
      "Ajout colonne =  5\n",
      "modèle de référence :  [-0.15150719 -0.13009139 -0.10197748 -0.14022774 -0.11004438] -0.126769634484864\n",
      "(398, 3)\n",
      "Ajout colonne =  6\n",
      "modèle de référence :  [-0.14878915 -0.12793797 -0.10092474 -0.13974282 -0.10217814] -0.1239145616719182\n",
      "(398, 37)\n",
      "Ajout colonne =  7\n",
      "modèle de référence :  [-0.15140792 -0.12472764 -0.09821258 -0.13775166 -0.10165919] -0.12275179844037618\n"
     ]
    }
   ],
   "source": [
    "# Transfromation des données et Amélioration (?) des résultats\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False) # aller voir la document (ou ex plus haut)\n",
    "\n",
    "for col  in [0,5,6,7]: # pour chacune de ces colonnes discrètes, \n",
    "    # Construire la matrice Xtmp one-hot des occurences de variables discrètes\n",
    "    # Concaténer Xtmp avec Xr\n",
    "    ###  TODO  ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## B.4. Histogramme de valeurs\n",
    "\n",
    "Il est parfois intéressant de convertir une variable continue en un histogramme de valeurs. Sur la colonne 1 des données, on avait l'impression qu'il y avait des comportements un peu similaire par groupe de valeurs... On a donc ajouté des catégories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation de la caractéristique 5 (Année)\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "dim = 1 # dimension à encoder\n",
    "#print(X[:10,dim])\n",
    "enc = KBinsDiscretizer(n_bins=4, encode='onehot', strategy='uniform') # comprendre la signification des arguments\n",
    "Xtmp = enc.fit_transform(X[:,dim].reshape(-1,1)).toarray()\n",
    "#print(Xtmp[:10,:])\n",
    "Xr = np.concatenate((Xr, Xtmp), axis = 1)\n",
    "sc = cross_val_score( mod, Xr, Y, scoring='neg_mean_absolute_percentage_error')\n",
    "print(Xtmp.shape)\n",
    "print(\"modèle de référence : \",sc, sc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.5. Transformations arbitraires\n",
    "\n",
    "Enrichir les données construisant une colonne binaire qui vaut 1 pour les voitures de 4 cylindres de moins de 2500 en masse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# créer une colonne biaire qui recense les petites voitures (masse<2500) de 4 cylindres\n",
    "\n",
    "Xtmp = np.where(np.logical_and(X[:,0]==4, X[:,4]<2500), 1, 0).reshape(-1,1)\n",
    "Xr = np.concatenate((Xr, Xtmp), axis = 1)\n",
    "sc = cross_val_score( mod, Xr, Y, scoring='neg_mean_absolute_percentage_error')\n",
    "print(Xtmp.shape)\n",
    "print(\"modèle de référence : \",sc, sc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## B.6. Passage à un modèle de l'état de l'art\n",
    "\n",
    "Est ce que les variables construites ont du sens pour un modèle non-linéaire de type XGBoost?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passage à un modèle de l'état de l'art\n",
    "\n",
    "# XGboost\n",
    "\n",
    "import xgboost as xgb # !pip install xgboost # en cas de besoin\n",
    "\n",
    "bst = xgb.XGBRegressor()\n",
    "sc = cross_val_score( bst, Xr, Y, scoring='neg_mean_absolute_percentage_error')\n",
    "print(\"xgboost : \",sc, sc.mean())\n",
    "\n",
    "sc = cross_val_score( bst, X[:,:6], Y, scoring='neg_mean_absolute_percentage_error')\n",
    "print(\"xgboost (X origine): \",sc, sc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Construction d'une chaine de traitements en scikit-learn\n",
    "\n",
    "## C.1. Cas d'usage: sélection de caractéristique\n",
    "\n",
    "1. Construire des données bruitées\n",
    "2. Construire un sélecteur de variables pertinentes \n",
    "    * Afin de prolonger le TP précedent, on choisit de construire un sélecteur basé sur la corrélation... En utilisant l'héritage pour une parfaite intégration dans la chaine\n",
    "3. L'intégrer dans la chaine (`Pipeline`)\n",
    "4. Vérifier:\n",
    "    * que la chaine est apprenable\n",
    "    * évaluable\n",
    "    * que les éléments de la chaine ont des dimensions raisonnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données + dimensions inutiles\n",
    "centers = [[-2.0, -2.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 1.5]\n",
    "X, y = make_blobs(n_samples=100, centers=centers, cluster_std=clusters_std,  n_features=2,   random_state=0) # 100 pts, 2classes, 2dim \n",
    "\n",
    "# ajout de bruit\n",
    "ndim_noise = 20\n",
    "Noise = np.random.randn(len(X), ndim_noise)*clusters_std[0]\n",
    "Xn = np.concatenate((X,Noise), axis=1)\n",
    "\n",
    "# split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction d'un estimateur sklearn calculant la corrélation des différentes features avec la cible\n",
    "# => fit ne fait rien\n",
    "# => score renvoie la somme des correlations des variables retenues\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Correl(BaseEstimator):\n",
    "    def fit(self,X,y):\n",
    "        return self\n",
    "    def score(self,X,y):\n",
    "        return np.sum(X.T@y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection de caractéristiques\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "estimator = Correl()\n",
    "selector = SequentialFeatureSelector(estimator, n_features_to_select=4) # j'utilise mon outil dans le selecteur sklearn\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "print(selector.get_support())\n",
    "\n",
    "# il est ensuite possible de filtrer les données:\n",
    "Xnew = selector.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de la chaine (pipeline)\n",
    "from sklearn.pipeline import Pipeline\n",
    "classif = svm.SVC(kernel = 'linear')\n",
    "# liste de tuples: titre + objet \n",
    "pipe = Pipeline([('sel. var',selector),('classif',classif)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vérification de l'usage et des propriétés du nouvel objet\n",
    "pipe.fit(X_train,y_train)           # 1. Apprentissage\n",
    "yhat = pipe.predict(X_test)         # 2. inférence\n",
    "tx = accuracy_score(yhat, y_test)   # 3. Evaluation (même si pipe n'entre pas directement en jeu)\n",
    "\n",
    "print(\"taux de bonne classif: \", tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification des dimensions du classifieur\n",
    "print(\"Dimension du classifieur: \", classif.coef_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.2. Même exercice avec une PCA & un arbre de décision\n",
    "\n",
    "**Exercice :** Construire une chaine composée de \n",
    "* Une projection PCA sur 3 axes \n",
    "* Un arbre de décision\n",
    "* Calculer la performance de cette chaine et afficher l'arbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "\n",
    "###  TODO  ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.3. Optimisation de la chaine de traitements\n",
    "\n",
    "La construction n'est pas une fin en soi: l'idée est de pouvoir optimiser la chaine à la fois au niveau des paramètres de pré-traitements et des hyper-paramètres.\n",
    "\n",
    "On veut tester les options suivantes (en combinaison):\n",
    "* Sélection de 2 à 5 variables (avec le sélecteur simple à base de correlation)\n",
    "* SVM\n",
    "    * noyau linéaire\n",
    "    * noyau gaussien avec `gamma = [0.1, 0.5, 1, 2, 5]`\n",
    "    * compromis de régularisation : `C = [0.1,1,5,10,100]`\n",
    "\n",
    "1. Construire la chaine de traitement\n",
    "2. Utiliser le `grid_search` vu dans le TP 1 pour optimiser l'ensemble\n",
    "    * Dans un premier temps, mettre tous les paramètres *en vrac* <BR>\n",
    "    https://scikit-learn.org/stable/tutorial/statistical_inference/putting_together.html\n",
    "    * Dans un second temps, essayer de ne pas calculer les combinaisons absurdes (tester toutes les valeurs de gamma pour un noyau linéaire) <BR>\n",
    "    Il faut faire des sous-dictionnaires\n",
    "\n",
    "3. Expliquer quelle chaine est retenue et à quel niveau de performances attendu\n",
    "\n",
    "> A votre avis, êtes-vous dans dans un cadre APP/TEST ou dans un cadre APP/VAL/TEST?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construction de la chaine (pipeline)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# V1 : test en vrac (~20 secondes sur mon ordinateur portable)\n",
    "\n",
    "# v2 : test raisonnable (~3.5 secondes sur mon ordinateur portable)\n",
    "\n",
    "### MISE EN PLACE DE LA CHAINE ###\n",
    "classif = svm.SVC()\n",
    "# liste de tuples: titre + objet \n",
    "pipe = Pipeline([('selvar',selector),('classif',classif)])\n",
    "\n",
    "# paramètres en vrac: TITRE__para: [valeurs à tester]\n",
    "# V1\n",
    "grid = {\n",
    "    \"selvar__n_features_to_select\": [2, 3, 4, 5],\n",
    "    \"classif__C\": [0.1,1,5,10,100],\n",
    "    \"classif__gamma\": [0.1, 0.5, 1, 2, 5],\n",
    "    \"classif__kernel\": [\"linear\",\"rbf\"],\n",
    "}\n",
    "#V2 avec sous-dictionnaire\n",
    "grid = [\n",
    "    {\"selvar__n_features_to_select\": [2, 3, 4, 5]},\n",
    "    {\"classif__C\": [0.1,1,5,10,100]},\n",
    "    {\"classif__kernel\": [\"linear\"]},\n",
    "    {\"classif__gamma\": [0.1, 0.5, 1, 2, 5],\n",
    "    \"classif__kernel\": [\"rbf\"]}\n",
    "]\n",
    "# param_grid = list(ParameterGrid(grid))\n",
    "# print(list(ParameterGrid(grid)))\n",
    "\n",
    "search = GridSearchCV(pipe, grid, n_jobs=2)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.4. Exercice\n",
    "\n",
    "Mêmes opérations que précédemment, mais:\n",
    "\n",
    "* Sur les données de qualité du vin\n",
    "* avec une normalisation standard\n",
    "* une random forest ou un XGBoost dont on fera varier le nombre et la profondeur des arbres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data/winequality-red.csv\"\n",
    "data = pd.read_csv(filename)\n",
    "X = data.values[:,:-1]\n",
    "Y = data.values[:,-1]\n",
    "# remise en forme des Y entre 0 et nClasses\n",
    "val = np.unique(Y)\n",
    "transf = dict(zip(val,np.arange(len(val)))) # mapping [x,y,z] => [0,1,2]\n",
    "y = np.vectorize(transf.get)(Y)             # application de la transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.5. Chaine de traitement et enrichissement des données\n",
    "\n",
    "Mêmes opérations que précédemment, mais en ajoutant des dimensions.\n",
    "\n",
    "La difficulté est de trouver l'objet scikit-learn qui permet d'insérer des colonnes dans les données\n",
    "\n",
    "* La chaine transformera les variables en catégories (one-hot) \n",
    "* Appliquera une régression logistique\n",
    "\n",
    "Le but est ensuite de chercher à optimiser une chaine de traitement contenant de l'enrichissement de données (par exemple, tester différentes valeurs pour la discrétisation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "features_id = [3]\n",
    "scale_id = [1,2]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"untouched\", StandardScaler(), scale_id ), # np.setdiff1d(np.arange(X.shape[1]), features_id)),\n",
    "        (\n",
    "            \"tobin\",\n",
    "            KBinsDiscretizer(n_bins=10, encode='onehot', strategy='uniform'),\n",
    "            features_id,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "#print(np.setdiff1d(np.arange(X.shape[1]), features_id))\n",
    "# print(preprocessor.fit_transform(X).toarray())\n",
    "print(X.shape)\n",
    "\n",
    "log_reg = make_pipeline(preprocessor, LogisticRegression())\n",
    "log_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "numeric_features = [\"age\", \"fare\"]\n",
    "numeric_transformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "categorical_features = [\"embarked\", \"pclass\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\n",
    "            \"cat\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    "            categorical_features,\n",
    "        ),\n",
    "    ],\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "log_reg = make_pipeline(preprocessor, SelectKBest(k=7), LogisticRegression())\n",
    "#log_reg.fit(X, y)\n",
    "\n",
    "sc = cross_val_score(log_reg, X, y)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction du sujet à partir de la correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  TODO )\",\" TODO \",\\\n",
    "    txt, flags=re.DOTALL))\n",
    "f2.close()\n",
    "\n",
    "### </CORRECTION> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "902a52bcf4503a473db011f1937bdfe17613b08622219712e0110e48c4958c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
